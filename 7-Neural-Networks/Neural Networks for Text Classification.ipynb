{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f34708",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "**Task:** Create a model that calculates the class (spam/ham) of a given message.\n",
    "\n",
    "We will do this by creating a Pipeline that will consist of 3 steps:\n",
    "\n",
    "- Vectorize the data (representing input and target as vectors)/\n",
    "- Transform the data.\n",
    "- Create a classification model on top of the new representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ba845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Transformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #Term frequency * inverse document frequency\n",
    "\n",
    "# Classifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('nn', MLPClassifier(hidden_layer_sizes=(100,50,), activation='tanh'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a26ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7972ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe.predict(['Die... I accidentally deleted e msg i suppose 2 put in e sim archive. Haiz... I so sad...'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e393c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.inverse_transform(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca0275",
   "metadata": {},
   "source": [
    "We can use `predict_proba` to estimate class probabilities and adjust the predictions to the context of the problem.\n",
    "\n",
    "For example, to decrease the \"risk tolerance\" of a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fdf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = pipe.predict_proba([\"you have received your package\"])\n",
    "ham_proba, spam_proba = probas[0]\n",
    "\n",
    "if spam_proba > 0.02:\n",
    "    out = 'spam'\n",
    "else:\n",
    "    out = 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7157315",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784251a",
   "metadata": {},
   "source": [
    "## Model persistence\n",
    "\n",
    "Scikit allows to save trained model objects as binary files (pickled) that can be read as part of an application (unrelated to scikit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4275091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipe, 'pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2b0c9",
   "metadata": {},
   "source": [
    "## Weights\n",
    "\n",
    "The coefficients obtained after the training process are stored within the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26308db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps[2][1].coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c04c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps[2][1].coefs_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps[2][1].coefs_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ed5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
